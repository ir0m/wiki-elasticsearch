services:
  elasticsearch:
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - "xpack.security.http.ssl.enabled=false"
    build:
      context: ./elasticsearch 
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - elastic-net
    healthcheck:
      test: ["CMD-SHELL", "curl -fs http://localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  kibana:
    image: docker.elastic.co/kibana/kibana:8.14.1
    container_name: kibana
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - elastic-net

  crawler:
    build: ./crawler  # ./crawler/Dockerfile を使ってビルド
    container_name: crawler
    depends_on:
      elasticsearch:
        condition: service_healthy # Elasticsearchが正常起動してから開始
    volumes:
      # ホストのpukiwiki_dataをコンテナの/pukiwiki_dataにマウント
      - ./pukiwiki_data:/pukiwiki_data
    # 起動時にインデックス作成と初回クロールを実行
    # 2回目以降は 'python crawler.py crawl' のみ実行すればOK
    command: >
      sh -c "sleep 10 && python crawler.py add-index && python crawler.py crawl"
    networks:
      - elastic-net

volumes:
  esdata:
    driver: local

networks:
  elastic-net:
    driver: bridge